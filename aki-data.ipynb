{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a291a0c6-78bc-4a04-89b5-fe794ee7c0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from importlib import reload  # Python 3.4+\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import lib.config as cfg\n",
    "import lib.preproc as preproc\n",
    "import lib.database as db\n",
    "import lib.ts_util as ts_util"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ab5dd3c-b3c9-4661-a52d-89b7900627fc",
   "metadata": {},
   "source": [
    "Run: systemctl start service postgresql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "131717d7-d21b-4a5b-8192-4e5c80e7b096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database: \n",
      "Username: postgres\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Password:  ········\n"
     ]
    }
   ],
   "source": [
    "con = db.connect_psql()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a648f0-31d2-4e45-b9b4-b809e8a83668",
   "metadata": {},
   "source": [
    "## Requires: import data to postgres\n",
    "- create tables/views: \n",
    "    - view_lab_creatinine_summary\n",
    "    - table_ts_lab\n",
    "    - table_lab_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9901777-09c6-4902-9c08-b15bcd943003",
   "metadata": {},
   "source": [
    "## Step 0: Normalization\n",
    "- Calcuate normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a104bf2-cc03-4b77-bf74-5980fca6439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected_lab = pd.read_sql_query(\"\"\" SELECT * FROM table_lab_stats\"\"\", con = con)\n",
    "df_selected_lab['mean'] = (df_selected_lab['val_max_mean'] + df_selected_lab['val_min_mean'])/2\n",
    "df_selected_lab['std'] = (df_selected_lab['val_max_std'] + df_selected_lab['val_min_std'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3cf264-b686-4923-aeff-bc2244e9c9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all pid with 20+ creatinine measurements\n",
    "query = \"\"\"\n",
    "SELECT DISTINCT\n",
    "    patientunitstayid\n",
    "FROM table_ts_lab\n",
    "\"\"\"\n",
    "\n",
    "df_pid = pd.read_sql_query(query, con)\n",
    "print('sample size: ', df_pid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc719a0-2653-4093-9981-578a98c9d51e",
   "metadata": {},
   "source": [
    "## Step 1: Calculate AKI label\n",
    "- run time: ~20 min\n",
    "- Calculate AKI label using sparse time series\n",
    "- Rule\n",
    "    - Rule 1: 1.5x baseline creatinine in 7 days\n",
    "    - Rule 2: 0.3mg/dL creatinine increase in 48h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a053fac-4d79-45fa-94da-e6abb6ae2ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "\t*\n",
    "FROM table_ts_lab\n",
    "WHERE labname = 'creatinine'\n",
    "ORDER BY patientunitstayid, tsid\n",
    "\"\"\"\n",
    "df_ts_label = pd.read_sql_query(query, con)\n",
    "df_ts_label['aki'] = 0\n",
    "pid_list = list(np.unique(df_ts_label['patientunitstayid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f61029-e1f8-4fe1-be94-4c9b59a3393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this takes ~ 20 minutes to run\n",
    "for pid in tqdm(pid_list, total=len(pid_list)):\n",
    "    df_ts_patient = df_ts_label[df_ts_label['patientunitstayid'] == pid]\n",
    "    \n",
    "    for i in range(1, len(df_ts_patient)):\n",
    "        dt_current = df_ts_patient.iloc[i]\n",
    "        ts_current = dt_current['tsid']\n",
    "        df_ts_patient_past = df_ts_patient.iloc[0:i]\n",
    "\n",
    "        # current row index in master label table\n",
    "        idx = dt_current.name\n",
    "\n",
    "        # Rule #1: 1.5x baseline creatinine in 7 days\n",
    "        df_temp = df_ts_patient_past[df_ts_patient_past['tsid'] > ts_current - 7*4]\n",
    "        if len(df_temp):\n",
    "            # creat_baseline = min(df_temp['value_min']) # baseline = 7-day min\n",
    "            # creat_baseline = np.median(df_temp['value_min']) # baseline = 7-day median\n",
    "            creat_baseline = np.percentile(df_temp['value_min'], 25) # baseline = 7-day 25 percentile\n",
    "            # creat_baseline = df_temp['value_min'].iloc[0] # baseline = 7-day start\n",
    "            if dt_current['value_max'] >= creat_baseline*1.5:\n",
    "                df_ts_label.loc[idx, 'aki'] = 1\n",
    "\n",
    "        # Rule #2: 0.3mg/dL creatinine increase in 48h\n",
    "        df_temp = df_ts_patient_past[df_ts_patient_past['tsid'] > ts_current - 2*4]\n",
    "        if len(df_temp):\n",
    "            creat_baseline = np.median(df_temp['value_min'])\n",
    "            if dt_current['value_max'] >= creat_baseline + 0.3:\n",
    "                df_ts_label.loc[idx, 'aki'] = 1\n",
    "\n",
    "df_ts_label.to_csv('./df_ts_label.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8102b0-ce4a-4c33-adef-2327b45838d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Under baseline = 7d median def: ~ 20% of sparse ts are labeled as 'aki positive'\n",
    "sum(df_ts_label['aki'])/len(df_ts_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae840049-e712-4e72-bdc6-6697ed7598ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9c1643f-c324-4f89-a7e4-fd35fb154a54",
   "metadata": {},
   "source": [
    "## Step 2: Prepare trainig dataset\n",
    "- run time: CPU heavy, ~2.5h\n",
    "- Use label: baseline creatinine use median\n",
    "- Function\n",
    "    - calculate categorical variables\n",
    "    - calculate lab variables\n",
    "    - fill sparse time series to dense time series\n",
    "    - calculate multi-head gt_label\n",
    "    - calculate multi-head aux tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab88bf20-62c5-453a-a8b4-61e78b923dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts_label_all = pd.read_csv('./df_ts_label_median.csv')\n",
    "df_ts_label_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3e94e0-68be-48d7-bd47-e48211f16929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# patient demographic\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    patient.patientunitstayid,\n",
    "    patient.gender,\n",
    "    patient.age,\n",
    "    patient.ethnicity, -- Caucasian, African American\n",
    "    patient.hospitaladmitsource -- Other Hospital, Emergency Department, Operating Room, Floor\n",
    "FROM patient patient\n",
    "\"\"\"\n",
    "df_patient = pd.read_sql_query(query, con)\n",
    "df_patient = df_pid.merge(df_patient, how='inner')\n",
    "\n",
    "# Drop rows with invalid gender\n",
    "df_patient = df_patient[df_patient['gender'] != '']\n",
    "df_patient = df_patient[df_patient['gender'] != 'Unknown']\n",
    "\n",
    "# Convert str age -> numerical age\n",
    "# patients age greater than 89 are expressed as '>89'\n",
    "df_patient['age'] = list(map(lambda x: int(x.replace('> ', '')), df_patient['age']))\n",
    "\n",
    "# map catigorical to numerical: gender\n",
    "df_patient['gender_female'] = list(map(lambda x: 0 if x == 'Male' else 1, df_patient['gender']))\n",
    "\n",
    "# Drop patient age <= 18\n",
    "df_patient = df_patient[df_patient['age'] > 18]\n",
    "\n",
    "df_patient['ethnicity_Caucasian'] = (df_patient['ethnicity'] == 'Caucasian').astype(int)\n",
    "df_patient['ethnicity_Black'] = (df_patient['ethnicity'] == 'African American').astype(int)\n",
    "df_patient['admission_Emergency'] = (df_patient['hospitaladmitsource'] == 'Emergency Department').astype(int)\n",
    "df_patient['admission_Floor'] = (df_patient['hospitaladmitsource'] == 'Floor').astype(int)\n",
    "df_patient['admission_Surgical'] = (df_patient['hospitaladmitsource'] == 'Operating Room').astype(int)\n",
    "df_patient['admission_Transfer'] = (df_patient['hospitaladmitsource'] == 'Other Hospital').astype(int)\n",
    "\n",
    "df_patient = df_patient.drop(['ethnicity', 'hospitaladmitsource', 'gender'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f32cc50-394a-48f5-bbc2-f438494045a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload preproc library\n",
    "preproc = reload(preproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fed0d24-4f24-4289-bd2f-0ce788b63299",
   "metadata": {},
   "source": [
    "### TBD\n",
    "- error pid=449988 / current # ts = 31\n",
    "- error: pid=2385766 / loop don't terminate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57565be-7b85-4ccc-b530-685e874c15f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_pid = df_pid['patientunitstayid']\n",
    "lab_columns = list(df_selected_lab['labname'])\n",
    "\n",
    "df_lab_agg = pd.DataFrame()\n",
    "\n",
    "for pid in tqdm(list_pid, total=len(list_pid)):\n",
    "    try:\n",
    "        df_timestamp_lab = preproc.get_df_timestamp_by_patient(pid, con)\n",
    "        df_timestamp_lab = df_timestamp_lab.rename(columns={'labname': 'variable'})\n",
    "\n",
    "        df_lab = preproc.calc_df_ts_from_timestamp(df_timestamp_lab, lab_columns)\n",
    "\n",
    "        # merge label into df_predictor\n",
    "        df_ts_label = df_ts_label_all[df_ts_label_all['patientunitstayid'] == pid][['patientunitstayid', 'tsid', 'aki']]\n",
    "        df_ts_label = df_lab[['patientunitstayid', 'tsid']].merge(df_ts_label, how='left')\n",
    "\n",
    "        list_label = df_ts_label['aki'].copy()\n",
    "        list_label = preproc.calc_list_label(list_label)\n",
    "\n",
    "        # label\n",
    "        df_lab['label_aki_gt'] = list_label\n",
    "        df_lab['label_aki_36h'] = preproc.calc_label_shift(list_label, 6)\n",
    "        df_lab['label_aki_24h'] = preproc.calc_label_shift(list_label, 4)\n",
    "        df_lab['label_aki_12h'] = preproc.calc_label_shift(list_label, 2)\n",
    "        df_lab['label_aki_6h'] = preproc.calc_label_shift(list_label, 1)\n",
    "\n",
    "        # aux task\n",
    "        df_aux_task = preproc.get_df_aux_task(df_lab)\n",
    "        df_lab = df_lab.join(df_aux_task)\n",
    "\n",
    "        df_lab_agg = df_lab_agg.append(df_lab.copy(), ignore_index=True)\n",
    "    except:\n",
    "        print('error: ', pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fabacc-ec2a-4c4e-af0c-6182c92a96cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_patient.merge(df_lab_agg)\n",
    "df_train.to_csv('./df_train.csv', index=False) # 700M\n",
    "df_train.to_pickle('df_train.pkl') # 3.7G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20c6a58-1451-4612-b88b-6d4c40704a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6848a8-e21d-4a06-afe9-b8579b459fab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03cd0aa5-d42c-47c8-a301-d09225fd3c40",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 3: Build trainig dataset\n",
    "- train/test split\n",
    "- define label/data columns\n",
    "- Missing value impute with -1\n",
    "- Normalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66273d43-bbfd-4277-8210-82e65b0273ed",
   "metadata": {},
   "source": [
    "## Step 3.1: train size = 8500\n",
    "- memory constraint"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8687d3f9-eb89-4b4a-adab-69495d77bce5",
   "metadata": {},
   "source": [
    "# train test split\n",
    "df_all = pd.read_pickle('df_train_median_all.pkl') # this is much faster than read from csv\n",
    "len(df_all)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "df8d46cd-9053-45dd-a6c2-512fe1a75d99",
   "metadata": {},
   "source": [
    "pid_list = np.unique(df_all['patientunitstayid'])\n",
    "df_train = pd.DataFrame({'patientunitstayid': pid_list[0:8500]}).merge(df_all, how='inner')\n",
    "df_train.to_pickle('df_train_median.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b0809b-88e1-4284-9822-7ac2543dea72",
   "metadata": {},
   "source": [
    "## Step 3.2: process training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad82029e-6547-41bd-9b63-a54e0ee8d385",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle('df_train_median.pkl') # this is much faster than read from csv\n",
    "pid_list = np.unique(df_train['patientunitstayid'])\n",
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdff31e5-85e8-4b62-ad35-6d98a5126e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def columns\n",
    "col_all = df_train.columns\n",
    "col_meta = ['patientunitstayid', 'tsid']\n",
    "col_label = list(col_all[list(map(lambda x: 'label_' in x, col_all))])\n",
    "col_label_used = col_label[1:] # remove gt_column\n",
    "col_regres = list(col_all[list(map(lambda x: 'regres_' in x, col_all))])\n",
    "col_to_drop = col_meta + col_label + col_regres\n",
    "\n",
    "# def max time series length\n",
    "max_ts_length = 128\n",
    "\n",
    "# build model cfg\n",
    "model_config = {\n",
    "    'col_to_drop': col_to_drop,\n",
    "    'col_label': col_label,\n",
    "    'col_regres': col_regres,\n",
    "    'max_ts_length': max_ts_length,\n",
    "}\n",
    "\n",
    "# Missing value impute with -1\n",
    "df_train = df_train.fillna(-1)\n",
    "\n",
    "# Normalization\n",
    "col_lab_min = list(map(lambda x: x+'_min', cfg.selected_lab))\n",
    "col_lab_max = list(map(lambda x: x+'_max', cfg.selected_lab))\n",
    "col_require_norm = col_lab_min + col_lab_max + col_regres\n",
    "\n",
    "for col in col_require_norm:\n",
    "    v_mean = np.mean(df_train[col])\n",
    "    v_std = np.std(df_train[col])\n",
    "\n",
    "    df_train[col] = (df_train[col] - v_mean)/v_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c187aa23-481f-4fed-93e2-1a9e912ed970",
   "metadata": {},
   "source": [
    "## [TBD] Step 3.3: process testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61453b24-a6e7-444f-8dea-6118cab02778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9265e186-07af-48d5-83a3-6cd70ed5b647",
   "metadata": {},
   "source": [
    "## Step 4: Build Fixed Size Tensor\n",
    "- Convert 2D flattened ts table: [pid, tsid], [feature]\n",
    "- To 3D tensor: [pid], [tsid], [feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9743f7e1-e978-41ea-be3f-d5a575ad98bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tensor_data = []\n",
    "list_tensor_label = []\n",
    "list_tensor_regres = []\n",
    "\n",
    "for pid in pid_list:\n",
    "    tensor_data, tensor_label, tensor_regres = ts_util.get_ts_by_pid(df_train, pid, model_config)\n",
    "\n",
    "    tensor_data = ts_util.build_fixed_length_ts(tensor_data, max_ts_length)\n",
    "    tensor_label = ts_util.build_fixed_length_ts(tensor_label, max_ts_length)\n",
    "    tensor_regres = ts_util.build_fixed_length_ts(tensor_regres, max_ts_length)\n",
    "\n",
    "    list_tensor_data.append(tensor_data)\n",
    "    list_tensor_label.append(tensor_label)\n",
    "    list_tensor_regres.append(tensor_regres)\n",
    "\n",
    "tensor_data_agg = torch.cat(list_tensor_data, dim=1)\n",
    "tensor_label_agg = torch.cat(list_tensor_label, dim=1)\n",
    "tensor_regres_agg = torch.cat(list_tensor_regres, dim=1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "57e10a2e-f730-4085-be1d-49ed17c12e42",
   "metadata": {},
   "source": [
    "torch.save(tensor_data_agg, './tensor_data_agg.pt')\n",
    "torch.save(tensor_label_agg, './tensor_label_agg.pt')\n",
    "torch.save(tensor_regres_agg, './tensor_regres_agg.pt')\n",
    "\n",
    "df_train_pid = df_train.drop_duplicates(subset=['patientunitstayid'])\n",
    "df_train_pid.to_csv('./df_train_pid.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
